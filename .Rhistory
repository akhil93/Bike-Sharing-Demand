sum(dbinom(60:160, size = 160, p = .28))
sum(dbinom(50:160, size = 160, p = .28))
qnorm(0.01)
qnorm(0.0066666666666667)
qnorm(0.05)
pnorm(70,80,10)
pnorm(70,80,10, lower.tail = TRUE)
qnorm(.95,1100,75)
qnorm(95,1100,75)
qnorm(.95,1100,75, lower.tail = FALSE)
ppois(10,lamda = 5*3)
ppois(10,lambda = 5*3)
pnorm(70,80,10, lower.tail = TRUE)
1-0.8413
qnorm(.95,1100,75)
qnorm(.95,1100,75, lower.tail = TRUE)
qnorm(.95,1100,75, lower.tail = FALSE)
dnorm(.95,1100,75, lower.tail = FALSE)
dnorm(.95,1100,75)
ppois(10,lambda = 5*3)
qnorm(.95,1100,75, lower.tail = TRUE)
MEAN = 0
for(i in 1:100){
a = qnorm(.95,1100,75, lower.tail = TRUE)
MEAN = MEAN + a
}
MEAN
pnorm(70,80,10)
qnorm(70,80,10)
pnorm(14,15,10)
0.4601722*2
pnorm(14:16,15,10)
0.5398278-0.4601722
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
summary(training)
plot(training$CompressiveStrength)
plot(training$FlyAsh)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
hist(training$Superplasticizer)
hist(log(training$Superplasticizer))
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
29/40
View(training)
grep("IL",colnames(training))
13*.8
new = princomp(training)
new = princomp(~., data =training)
new = training[,c(2,grep("IL",colnames(training)))]
prepro = preProcess(training,method = "pca", pcaComp = 2)
prepro = preProcess(training[,-1],method = "pca", pcaComp = 2)
summary(head(training[,1]))
modelFit <- train(training$diagnosis ~ .,method="glm",data=training)
summary(modelFit)
modelFit
hist(log(training$Superplasticizer))
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
hist(log(training$Superplasticizer))
summary(log(training$Superplasticizer))
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
pairs(training)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
grep("IL",colnames(training))
new = training[, grep("IL",colnames(training))]
modelFit <- train(~ .,method="glm",preProcess="pca",data=training)
hist(log(training$Superplasticizer))
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
hist(log(training$Superplasticizer))
hist(log(training$Superplasticizer+1))
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
preProc<-preProcess(smalltrain[,-1],method="pca")
trainPC<-predict(preProc,smalltrain[,-1])
SELECT<-which(grepl("^IL|^diagnosis", colnames(training), ignore.case = T))
smalltrain<-training[,SELECT]
preProc<-preProcess(smalltrain[,-1],method="pca")
trainPC<-predict(preProc,smalltrain[,-1])
grep("IL",colnames(training))
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
grep("IL",colnames(training))
View(training)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
View(training)
grep("IL",colnames(training))
smalltrain<-training[,(grepl("^IL|^diagnosis", colnames(training), ignore.case = T)]
select = which((grepl("^IL|^diagnosis", colnames(training), ignore.case = T))
)
select = which((grepl("^IL|^diagnosis", colnames(training), ignore.case = T)))
SELECT<-which(grepl("^IL|^diagnosis", colnames(training), ignore.case = T))
smalltrain<-training[,SELECT]
preProc<-preProcess(smalltrain[,-1],method="pca")
trainPC<-predict(preProc,smalltrain[,-1])
trainPC
summary(trainPC)
modelFit<-train(smalltrain$diagnosis~.,method="glm",data=trainPC)
modelFit
summary(modelFit)
9*.8
getwd()
data(mtcars)
summary(mtcars)
str(mtcars)
mtcars$am = as.factor(mtcars$am)
str(mtcars)
View(mtcars)
summary(mtcars$am)
par(mfrow = c(1,2))
hist(mtcars$am == 0, col = "steelblue")
hist(mtcars$am == "0", col = "steelblue")
hist(as.numeric(mtcars$am == "0"), col = "steelblue")
hist( mpg[which(as.numeric(mtcars$am == "0")], col = "steelblue" )
hist( mpg[which(as.numeric(mtcars$am == "0"))], col = "steelblue" )
hist( mtcars$mpg[which(as.numeric(mtcars$am == "0"))], col = "steelblue" )
mtcars$automatic = mtcars$am == 0
par(mfrow = c(1,2))
hist( mpg[which(automatic == TRUE)], data = mtcars, col = "steelblue" )
hist( mtcars$mpg[which(mtcars$automatic == TRUE)], col = "steelblue" )
hist( mtcars$mpg[which(mtcars$automatic == FALSE)], col = "steelblue" )
plot( mtcars$mpg[which(mtcars$automatic == FALSE)], col = "steelblue" )
plot( mtcars$mpg[which(mtcars$automatic == TRUE)], col = "red" )
max(mtcars$mpg[which(mtcars$automatic == TRUE)])
max(mtcars$mpg[which(mtcars$automatic == FALSE)])
model = lm(mpg ~ wt, data = mtcars)
summary(model)
model = lm(mpg ~ automatic, data = mtcars)
summary(model)
model = lm(mpg ~ automatic == FALSE, data = mtcars)
summary(model)
model2 = lm(mpg ~ wt + automatic, data = mtcars)
summary(model2)
model.fs = lm(automatic ~ wt, data = mtcars) # first stage.
model.IV = lm( mpg ~ model.fs$fitted.values, data = mtcars)
summary(model.IV)
par(mfrow = c(1,2))
hist( model$residuals )
hist( model.IV$residuals )
render("MotorTrend.Rmd", "MotorTrend.pdf")
pandoc(MotorTrend.Rmd, format = "pdf")
library(knitr)
pandoc(MotorTrend.Rmd, format = "pdf")
render("MotorTrend.Rmd", "MotorTrend.pdf")
pandoc(MotorTrend.Rmd, format = "pdf")
pandoc(MotorTrend.Rmd, format = "pdf")
sessionInfo()
?shuttle
install.packages("MASS")
?shuttle
library(MASS)
?shuttle
data(shuttle)
str(shuttle)
table(shuttle$use)
summary(glm(shuttle$use == "auto" ~ shuttle$wind , family="binomial"))
qm1 = glm(shuttle$use == "auto" ~ shuttle$wind , family="binomial")
qm1
exp(qm1$coeff)
exp(confint(qm1$coeff))
exp(confint(qm1))
summary(glm(shuttle$use ~ shuttle$wind + shuttle$magn, family="binomial"))
qm2 = glm(shuttle$use ~ shuttle$wind + shuttle$magn, family="binomial")
exp(qm2$coeff)
confint(exp(qm2))
exp(confint(qm2))
levels(shuttle$use) = c(0,1)
str(shuttle)
table(shuttle$use)
qm1 = glm(shuttle$use == 1 ~ shuttle$wind, family = binomial)
summary(qm1)
qm1 = glm(shuttle$use == 1 ~ as.factor(shuttle$wind), family = binomial)
summary(qm1)
qm1 = glm(shuttle$use == 1 ~ shuttle$wind == "head", family = binomial)
summary(qm1)
qm1 = glm(shuttle$use == 1 ~ shuttle$wind == 0, family = binomial)
summary(qm1)
summary(logRegshuttle <- glm(use ~ wind,family="binomial", data=shuttle ))
logRegshuttle <- glm(use ~ wind,family="binomial", data=shuttle )
exp(logRegshuttle)/(1-exp(logRegshuttle))
exp(logRegshuttle$coeff)/(1-exp(logRegshuttle$coeff))
str(shuttle)
levels(shuttle$wind) = c("head","tail")
str(shuttle)
logRegshuttle <- glm(use ~ as.factor(wind),family="binomial", data=shuttle )
summary(logRegshuttle)
.25131/.03181
exp(-0.25131)/exp(-0.03181)
rm(shuttle)
rm(logRegshuttle,qm1,qm2)
data(shuttle)
str(shuttle)
summary(glm(shuttle$use ~ shuttle$wind + shuttle$magn, family="binomial"))
summary(glm(use ~ wind, data = shuttle, family = "binomial"))
summary(glm(use ~ wind-1, data = shuttle, family = "binomial"))
exp(-0.2513)/(exp(-0.2831))
exp(-0.2513)/exp(-0.2831)
exp(-0.2513)/(1-exp(-0.2831))
data(InsectSprays)
str(InsectSprays)
summary(glm(count ~ as.factor(spray), data = InsectSprays,family = "poission"))
summary(glm(count ~ as.factor(spray), data = InsectSprays,family = "poisson"))
summary(glm(count ~ as.factor(spray)-1, data = InsectSprays,family = "poisson"))
exp(2.67415)/exp(2.73003)
summary(glm(use ~ wind-1, data = shuttle))
data(shuttle)
str(shuttle)
summary(glm(use ~ wind-1, data = shuttle))
summary(glm(use ~ wind, data = shuttle))
summary(glm(use ~ wind-1, data = shuttle, family = "binomial"))
exp(-0.2513)/exp(-0.2831)
summary(glm(shuttle$use ~ shuttle$wind + shuttle$magn, family="binomial"))
summary(glm(shuttle$use ~ shuttle$wind + shuttle$magn-1, family="binomial"))
exp(-3.635e-01)/exp(-3.955e-01)
exp(-3.635e-01 )/exp(-3.201e-02)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
str(vowel.train)
str(vowel.test)
vowel.train$y = as.factor(vowel.train$y)
vowel.test$y = as.factor(vowel.test$y)
str(vowel.train)
str(vowel.test)
library(caret)
train(y ~., data = vowel.train, method = "randomForest")
set.seed(33833)
train(y ~., data = vowel.train, method = "gbm")
model = train(y ~., data = vowel.train, method = "gbm")
model = train(y ~., data = vowel.train, method = "rf")
rf.ped = predict(model, newdata = vowel.test)
summary(rf.ped)
table(rf.ped, vowel.test)
model = randomForest(y ~., data = vowel.train)
model
p = predict(model, vowel.test)
table(p,vowel.test )
table(p,vowel.test)
table(p,vowel.test$y)
sum(diag(table(p,vowel.test$y)))
277/462
model = gbm(y ~., data = vowel.train)
p = predict(model, vowel.test)
sum(diag(table(p,vowel.test$y)))
model = gbm(y ~., data = vowel.train, n.tree = 100)
p = predict(model, vowel.test)
table(p,vowel.test$y)
model = train(y ~., data = vowel.train, method = "randomForest")
model = train(y ~., data = vowel.train, method = "RF")
model = train(y ~., data = vowel.train, method = "rf")
p = predict(model, vowel.test)
table(p,vowel.test$y)
sum(diag(table(p,vowel.test$y)))/462
model = train(y ~., data = vowel.train, method = "gbm")
library(MASS)
?shuttle
data(shuttle)
str(shuttle)
names(shuttle)
?glm
fit <- glm(use ~ wind, family='binomial', shuttle)
exp(fit$coeff)
fit <- glm(use ~ wind + as.factor(magn), family='binomial', shuttle)
exp(fit$coeff)
0.7777778/0.9686888
0.6952323 /0.9684981
data(InsectSprays)
outp <- exp(coef(glm(count ~ as.factor(spray) - 1, family="poisson", InsectSprays)))
outp
outp[1]/outp[2]
?offset
log(10)
glm(count ~ x + offset(t), family = poisson)
library(ElemStatLearn)
library(plyr)
data(vowel.train)
data(vowel.test)
vowel.train <- mutate(vowel.train,y=factor(y))
vowel.test <- mutate(vowel.test,y=factor(y))
library(caret)
set.seed(33833)
rf.mdl <- train(y~.,data=vowel.train,method="rf",verbose=FALSE,metric="Accuracy")
gbm.mdl <- train(y~.,data=vowel.train,method="gbm",verbose=FALSE,metric="Accuracy")
pred.rf <- predict(rf.mdl,vowel.test)
pred.gbm <- predict(gbm.mdl,vowel.test)
confusionMatrix(pred.rf,vowel.test$y)$overall["Accuracy"]
confusionMatrix(pred.gbm,vowel.test$y)$overall["Accuracy"]
idx <- pred.rf == pred.gbm
pred.comb <- pred.rf[idx]
test.comb <- vowel.test[idx,"y"]
confusionMatrix(pred.comb,test.comb)$overall["Accuracy"]
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
lasso.mdl <- train(CompressiveStrength~.,data=training,method="lasso",
metric="RMSE")
plot(lasso.mdl$finalModel,xvar="penalty",use.color=TRUE)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
lasso.mdl <- train(CompressiveStrength~.,data=training,method="lasso",
metric="RMSE")
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
lasso.mdl <- train(CompressiveStrength~.,data=training,method="lasso",
metric="RMSE")
install.packages("elasticnet")
install.packages("yhat")
library(yhat)
install.packages("yhatr")
library(yhatr)
shiny::runApp('GitHub/Developing-Data-Products')
mean(1:1337)
a <- (1, 2, 3, 4, 5)
a <- c(1, 2, 3, 4, 5)
b <- c( 6, 7, 8, 9, 10)
a+b
c <- a*b
d <- c(1:10, 30:40, 5, 7, 9, 12)
median(d)
sum(d)
length <- rnorm(10, 180, 10)
weight <- (length/100)^2 * 25
measurements <- data.frame(cbind(length, weight))
measurements <- round(measurements,4)
measurements
sales <- c(1:10)
sales
aggregate(sales)
sum(sales)
library(mtcars)
data(mtcars)
mtcars <- mtcars
View(mtcars)
a <- mtcars[order(hp)]
a <- mtcars[order(hp),]
a <- mtcars[order(mtcars$hp),]
a
install.packages("h2o")
library(h20)
?summary()
help(Summary)
setwd("C:/Users/Akhilkumar/Documents/GitHub/Bike-Sharing-Demand")
train <- read.csv("train.csv", header = T)
test <- read.csv("test.csv", header = T)
train$casual <- NULL
train$registered <- NULL
test$count <- 0
com.data <- rbind(train,test)
train$type <- TRUE
test$type <- FALSE
com.data <- rbind(train,test)
View(com.data)
View(com.data)
com.data$datetime <- strptime(com.data$datetime, format="%Y-%m-%d %H:%M:%S")
com.data$hour <- as.factor(com.data$datetime$hour)
com.data$wday <- as.factor(com.data$datetime$wday)
com.data$month <- as.factor(com.data$datetime$month)
com.data$year <- as.factor(com.data$datetime$year + 1900)
View(com.data)
com.data$month <- as.factor(com.data$datetime$mon)
View(com.data)
com.data$datetime <- NULL
train <- subset(com.data, type == TRUE)
test <- subset(com.data, type == FALSE)
str(train)
com.data$season <- as.factor(com.data$season)
com.data$holiday <- as.factor(com.data$holiday)
com.data$workingday <- as.factor(com.data$workingday)
com.data$weather <- as.factor(com.data$weather)
train <- subset(com.data, type == TRUE)
test <- subset(com.data, type == FALSE)
str(train)
write.csv(train, file = "newtrain.csv", col.names = TRUE)
qqnorm(as.numeric(train$season))
qqnorm(as.numeric(train$weather))
qqnorm(as.numeric(train$holiday))
qqnorm(as.numeric(train$workingday))
qqnorm(as.numeric(train$temp))
qqline(as.numeric(train$temp, col = 2))
qqline(as.numeric(train$temp), col = 2)
library(robCompositions)
adtest(train)
train1 <- train
train1 <- as.numeric(train1)
train1$season <- as.integer(train1$season)
train1$weather <- as.integer(train1$weather)
train1$holiday <- as.integer(train1$holiday)
train1$workingday <- as.integer(train1$workingday)
View(train1)
train1$hour <- as.integer(train1$hour)
train1$wday <- as.integer(train1$wday)
train1$year <- as.integer(train1$year)
train1$month <- as.integer(train1$month)
train1$type <- NULL
adtest(train1)
par(mfrow = c(2,2))
qqnorm(train$temp)
qqline(train$temp, col = 2)
qqnorm(train$atemp)
qqline(train$atemp, col = 2)
qqnorm(train$humidity)
qqline(train$humidity, col = 2)
qqnorm(train$windspeed)
qqline(train$windspeed, col = 2)
par(mfrow = c(2,2))
qqnorm(train$temp,main = "Q-Q Plot of Temperature")
qqline(train$temp, col = 2)
qqnorm(train$atemp,main = "Q-Q Plot of Feel-Like Temperature")
qqline(train$atemp, col = 2)
qqnorm(train$humidity,main = "Q-Q Plot of Humidity")
qqline(train$humidity, col = 2)
qqnorm(train$windspeed,main = "Q-Q Plot of Windspeed")
qqline(train$windspeed, col = 2)
t.test(train$cout, train$temp)
t.test(train$count, train$temp)
t.test(train$count, train$atemp)
t.test(train$count, train$huidity)
t.test(train$count, train$humidity)
t.test(train$count, train$windspeed)
t.test(train$count)
shapiro.test(train$temp)
t.test(train$temp)
ks.test(train$temp)
ks.test(train$count,train$temp)
t.test(train$temp)
t.test(as.numeric(train$season))
t.test(train$season)
t.test(as.numeric(train$weather))
t.test(as.numeric(train$holiday))
t.test(as.numeric(train$working))
t.test(as.numeric(train$workingday))
t.test(as.numeric(train$count))
t.test(as.numeric(train$hour))
t.test(as.numeric(train$wday))
t.test(as.numeric(train$year))
